#!/usr/bin/env python3
"""
Test script for the updated LMStudio integration using the official SDK.

This script tests the updated implementation to ensure it works correctly
with the official LMStudio SDK instead of the OpenAI-compatible API.
"""

import sys
import os

# Add the src directory to the path so we can import our package
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from neo4j_lmstudio.core.client import get_client, LMStudioClient
from neo4j_lmstudio.core.llm import LMStudioLLM
from neo4j_lmstudio.core.embeddings import LMStudioEmbedder


def test_client_connection():
    """Test basic client connection and configuration."""
    print("üîß Testing LMStudio client connection...")
    
    try:
        client = get_client()
        print(f"‚úÖ Client created successfully")
        print(f"   Server host: {client.server_host}")
        print(f"   Default chat model: {client.default_chat_model}")
        print(f"   Default embedding model: {client.default_embedding_model}")
        
        # Test health check
        is_healthy = client.health_check()
        print(f"   Health check: {'‚úÖ Pass' if is_healthy else '‚ùå Fail'}")
        
        return True
    except Exception as e:
        print(f"‚ùå Client connection failed: {e}")
        return False


def test_llm_functionality():
    """Test LLM functionality with the official SDK."""
    print("\nü§ñ Testing LLM functionality...")
    
    try:
        llm = LMStudioLLM()
        print("‚úÖ LLM instance created")
        
        # Test simple invoke
        response = llm.invoke("What is 2 + 2?")
        print(f"‚úÖ Simple invoke successful")
        print(f"   Response: {response[:100]}...")
        
        # Test with system instruction
        system_response = llm.invoke(
            "What is the capital of France?",
            system_instruction="You are a helpful geography assistant."
        )
        print(f"‚úÖ System instruction invoke successful")
        print(f"   Response: {system_response[:100]}...")
        
        # Test model info
        model_info = llm.get_model_info()
        print(f"‚úÖ Model info retrieved")
        print(f"   Provider: {model_info.get('provider')}")
        print(f"   Using official SDK: {model_info.get('using_official_sdk')}")
        
        return True
    except Exception as e:
        print(f"‚ùå LLM test failed: {e}")
        return False


def test_embedding_functionality():
    """Test embedding functionality with the official SDK."""
    print("\nüî§ Testing embedding functionality...")
    
    try:
        embedder = LMStudioEmbedder()
        print("‚úÖ Embedder instance created")
        
        # Test single text embedding
        text = "This is a test sentence for embedding."
        embedding = embedder.embed_query(text)
        print(f"‚úÖ Single embedding successful")
        print(f"   Embedding dimensions: {len(embedding)}")
        
        # Test multiple document embeddings
        texts = [
            "First document to embed",
            "Second document to embed", 
            "Third document to embed"
        ]
        embeddings = embedder.embed_documents(texts)
        print(f"‚úÖ Multiple embeddings successful")
        print(f"   Number of embeddings: {len(embeddings)}")
        print(f"   Each embedding dimensions: {len(embeddings[0]) if embeddings else 0}")
        
        # Test model info
        model_info = embedder.get_model_info()
        print(f"‚úÖ Embedding model info retrieved")
        print(f"   Provider: {model_info.get('provider')}")
        print(f"   Using official SDK: {model_info.get('using_official_sdk')}")
        
        return True
    except Exception as e:
        print(f"‚ùå Embedding test failed: {e}")
        return False


def test_chat_functionality():
    """Test chat functionality with the official SDK."""
    print("\nüí¨ Testing chat functionality...")
    
    try:
        client = get_client()
        
        # Test getting a chat instance
        chat = client.get_chat("You are a helpful assistant.")
        print("‚úÖ Chat instance created")
        
        # Test LLM with chat session
        llm = LMStudioLLM()
        chat_session = llm.create_chat_session("You are a math tutor.")
        print("‚úÖ Chat session created")
        
        return True
    except Exception as e:
        print(f"‚ùå Chat test failed: {e}")
        return False


def test_model_listing():
    """Test model listing functionality."""
    print("\nüìã Testing model listing...")
    
    try:
        client = get_client()
        
        # Test downloaded models
        try:
            downloaded_models = client.list_downloaded_models()
            print(f"‚úÖ Downloaded models retrieved: {len(downloaded_models)} models")
        except Exception as e:
            print(f"‚ö†Ô∏è  Downloaded models listing failed (may be normal): {e}")
        
        # Test loaded models
        try:
            loaded_models = client.list_loaded_models()
            print(f"‚úÖ Loaded models retrieved: {len(loaded_models)} models")
        except Exception as e:
            print(f"‚ö†Ô∏è  Loaded models listing failed (may be normal): {e}")
        
        return True
    except Exception as e:
        print(f"‚ùå Model listing test failed: {e}")
        return False


def main():
    """Run all tests."""
    print("üöÄ Testing LMStudio Official SDK Integration")
    print("=" * 50)
    
    tests = [
        test_client_connection,
        test_llm_functionality,
        test_embedding_functionality,
        test_chat_functionality,
        test_model_listing,
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"‚ùå Test {test.__name__} crashed: {e}")
    
    print("\n" + "=" * 50)
    print(f"üìä Test Results: {passed}/{total} tests passed")
    
    if passed == total:
        print("üéâ All tests passed! The official SDK integration is working correctly.")
        return 0
    else:
        print("‚ö†Ô∏è  Some tests failed. Check LMStudio server and model availability.")
        return 1


if __name__ == "__main__":
    exit(main())
